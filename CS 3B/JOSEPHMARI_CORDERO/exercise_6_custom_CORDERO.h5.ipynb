{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba3c7b4",
   "metadata": {},
   "source": [
    "# Exercise 6: Custom CNN with VGG16 Architecture\n",
    "## Student: JOSEPHMARI CORDERO\n",
    "## Dataset: Cats vs Dogs Classification\n",
    "\n",
    "This notebook implements a CNN using VGG16 transfer learning architecture.\n",
    "\n",
    "**Dataset**: Cats vs Dogs (Custom dataset - 25 points)\n",
    "**Architecture**: VGG16 with Transfer Learning (50 points)\n",
    "\n",
    "AI was used to help generate the codebase\n",
    "\n",
    "Note: Make sure that the tensorflow package is installed in your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479aca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET DIRECTORY CONFIGURATION\n",
    "# Using Cats vs Dogs dataset\n",
    "# You can download from: https://www.kaggle.com/datasets/salader/dogs-vs-cats\n",
    "# Or use your own custom dataset with similar structure\n",
    "\n",
    "train_dir = \"cats_dogs_dataset/train\"  # Update with your dataset path\n",
    "test_dir = \"cats_dogs_dataset/test\"    # Update with your dataset path\n",
    "\n",
    "print(\"Dataset directories configured:\")\n",
    "print(f\"Training: {train_dir}\")\n",
    "print(f\"Testing: {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PARAMETERS\n",
    "# VGG16 requires 224x224 input size\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "print(f\"Image size: {IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Training epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING & AUGMENTATION\n",
    "# Enhanced augmentation for better generalization\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n",
    "print(f\"Classes: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b252d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 ARCHITECTURE WITH TRANSFER LEARNING\n",
    "\n",
    "# Load pre-trained VGG16 model without top layers\n",
    "print(\"Loading VGG16 base model (pre-trained on ImageNet)...\")\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model layers (we'll only train the custom top layers)\n",
    "base_model.trainable = False\n",
    "\n",
    "print(\"\\nBase VGG16 Model Summary:\")\n",
    "base_model.summary()\n",
    "\n",
    "# Build the complete model with custom classification head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE VGG16 MODEL WITH CUSTOM LAYERS\")\n",
    "print(\"=\"*70)\n",
    "model.summary()\n",
    "\n",
    "# Count parameters\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "non_trainable_params = sum([tf.size(w).numpy() for w in model.non_trainable_weights])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {non_trainable_params:,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23690b77",
   "metadata": {},
   "source": [
    "## VGG16 Architecture Details\n",
    "\n",
    "### **What is VGG16?**\n",
    "VGG16 is a convolutional neural network architecture developed by the Visual Geometry Group (VGG) at Oxford. It was a runner-up in the 2014 ImageNet competition.\n",
    "\n",
    "### **Architecture Highlights:**\n",
    "1. **16 Weight Layers**: 13 convolutional layers + 3 fully connected layers\n",
    "2. **Small Filters**: Uses only 3x3 convolution filters throughout\n",
    "3. **Deep Network**: Stacks multiple conv layers before pooling\n",
    "4. **Pre-trained Weights**: Trained on ImageNet (1.4M images, 1000 classes)\n",
    "\n",
    "### **Transfer Learning Approach:**\n",
    "1. **Base Model (Frozen)**: VGG16 pre-trained layers extract features\n",
    "2. **Custom Head (Trainable)**: \n",
    "   - Flatten layer\n",
    "   - Dense(256) + Dropout(0.5) with L2 regularization\n",
    "   - Dense(128) + Dropout(0.5) with L2 regularization\n",
    "   - Output Dense(1) with sigmoid activation\n",
    "\n",
    "### **Benefits:**\n",
    "- Leverages learned features from ImageNet\n",
    "- Faster training with smaller datasets\n",
    "- Better generalization\n",
    "- Reduced overfitting with dropout and L2 regularization\n",
    "\n",
    "### **Improvements Applied:**\n",
    "- **L2 Regularization**: Weight decay = 0.001\n",
    "- **Dropout Layers**: 50% dropout rate\n",
    "- **Data Augmentation**: Rotation, shift, zoom, flip, shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE THE MODEL\n",
    "\n",
    "# Use Adam optimizer with lower learning rate for transfer learning\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(f\"Optimizer: Adam (lr=0.0001)\")\n",
    "print(f\"Loss: Binary Crossentropy\")\n",
    "print(f\"Metrics: Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f11d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP CALLBACKS\n",
    "\n",
    "# ModelCheckpoint: Save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'exercise_6_custom_Cordero.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EarlyStopping: Stop training if validation loss doesn't improve\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stopping]\n",
    "\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"✓ ModelCheckpoint: Saves best model based on validation accuracy\")\n",
    "print(\"✓ EarlyStopping: Stops if validation loss doesn't improve for 5 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE VGG16 MODEL\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING TRAINING WITH VGG16 TRANSFER LEARNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model saved as: exercise_6_custom_Cordero.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE TRAINING HISTORY\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o', linewidth=2)\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s', linewidth=2)\n",
    "ax1.set_title('VGG16 Model Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history.history['loss'], label='Training Loss', marker='o', linewidth=2)\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s', linewidth=2)\n",
    "ax2.set_title('VGG16 Model Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Loss', fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_VGG16_Cordero.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history plot saved as: training_history_VGG16_Cordero.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE THE VGG16 MODEL\n",
    "\n",
    "print(\"Evaluating model on test data...\")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VGG16 MODEL PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Display final training metrics\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "print(\"\\nFinal Training Metrics:\")\n",
    "print(f\"Training Accuracy: {final_train_acc * 100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {final_val_acc * 100:.2f}%\")\n",
    "print(f\"Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Validation Loss: {final_val_loss:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AND TEST SAVED MODEL\n",
    "\n",
    "print(\"Loading saved model from disk...\")\n",
    "loaded_model = tf.keras.models.load_model('exercise_6_custom_Cordero.h5')\n",
    "\n",
    "print(\"\\nTesting loaded model...\")\n",
    "loaded_loss, loaded_acc = loaded_model.evaluate(test_generator, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADED MODEL VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Loaded Model Test Accuracy: {loaded_acc * 100:.2f}%\")\n",
    "print(f\"Loaded Model Test Loss: {loaded_loss:.4f}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n✓ Model successfully saved and loaded!\")\n",
    "print(f\"✓ File: exercise_6_custom_Cordero.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75729df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION FUNCTION\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_image(img_path, model_path='exercise_6_custom_Cordero.h5'):\n",
    "    \"\"\"\n",
    "    Predict the class of an image using the trained VGG16 model\n",
    "    Args:\n",
    "        img_path: Path to the image file\n",
    "        model_path: Path to the trained model\n",
    "    Returns:\n",
    "        label: Predicted class label\n",
    "        confidence: Prediction confidence (0-1)\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    pred = model.predict(img_array, verbose=0)[0,0]\n",
    "    \n",
    "    # Determine label based on class indices\n",
    "    # Adjust these labels based on your actual dataset classes\n",
    "    label = \"Class 1\" if pred >= 0.5 else \"Class 0\"\n",
    "    confidence = pred if pred >= 0.5 else (1 - pred)\n",
    "    \n",
    "    print(f\"Image: {img_path}\")\n",
    "    print(f\"Prediction: {label}\")\n",
    "    print(f\"Confidence: {confidence * 100:.2f}%\")\n",
    "    print(f\"Raw score: {pred:.4f}\")\n",
    "    print(f\"{'-'*50}\\n\")\n",
    "    \n",
    "    return label, confidence\n",
    "\n",
    "print(\"Prediction function defined successfully!\")\n",
    "print(\"Usage: predict_image('path/to/image.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545704a4",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "\n",
    "### Assignment Requirements Met:\n",
    "\n",
    "#### ✅ **Part 1: Custom Dataset (25 points)**\n",
    "- **Dataset Used**: Cats vs Dogs\n",
    "- **Dataset Source**: Custom dataset (not Muffin vs Chihuahua)\n",
    "- **Classes**: Binary classification (2 classes)\n",
    "- **Dataset Structure**: Train and test directories with proper organization\n",
    "\n",
    "#### ✅ **Part 2: CNN Architecture Selection (50 points)**\n",
    "- **Architecture**: VGG16 with Transfer Learning\n",
    "- **Why VGG16?**\n",
    "  - Deep architecture (16 layers)\n",
    "  - Pre-trained on ImageNet\n",
    "  - Proven performance on image classification\n",
    "  - Excellent for transfer learning\n",
    "  \n",
    "### Model Specifications:\n",
    "- **Input Size**: 224x224x3 (RGB images)\n",
    "- **Base Model**: VGG16 (frozen, pre-trained on ImageNet)\n",
    "- **Custom Layers**: \n",
    "  - Flatten\n",
    "  - Dense(256) + Dropout(0.5) + L2 regularization\n",
    "  - Dense(128) + Dropout(0.5) + L2 regularization\n",
    "  - Dense(1) with sigmoid activation\n",
    "- **Total Parameters**: ~15M (most frozen)\n",
    "- **Trainable Parameters**: ~2M (custom layers only)\n",
    "\n",
    "### Training Configuration:\n",
    "- **Optimizer**: Adam (lr=0.0001)\n",
    "- **Loss**: Binary Crossentropy\n",
    "- **Batch Size**: 32\n",
    "- **Epochs**: 20 (with early stopping)\n",
    "- **Data Augmentation**: Rotation, shift, zoom, flip, shear\n",
    "- **Regularization**: L2 (0.001) + Dropout (0.5)\n",
    "\n",
    "### Files Generated:\n",
    "1. **exercise_6_custom_Cordero.h5** - Trained model\n",
    "2. **training_history_VGG16_Cordero.png** - Training plots\n",
    "\n",
    "### Student: JOSEPHMARI CORDERO"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
